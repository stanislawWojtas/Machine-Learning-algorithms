{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Dimensionality reduction"
      ],
      "metadata": {
        "id": "jUFGY989-Iwq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prepare the data"
      ],
      "metadata": {
        "id": "Lkg6zJYs-FzL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets\n",
        "data_breast_cancer = datasets.load_breast_cancer()\n",
        "data_iris = datasets.load_iris()"
      ],
      "metadata": {
        "id": "awsC-IjX99KN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA"
      ],
      "metadata": {
        "id": "lFAm3wBB-fog"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PCA for breast_cancer dataset\n",
        "\n",
        "X_bc = data_breast_cancer.data\n",
        "y_bc = data_breast_cancer.target\n",
        "# we create PCA object to cover 90% of the variation\n",
        "pca_bc = PCA(n_components=0.9)\n",
        "X_bc90 = pca_bc.fit_transform(X_bc)\n",
        "print(pca_bc.explained_variance_ratio_)\n",
        "# Now we scale the data to get better results\n",
        "X_bc_sc = StandardScaler().fit_transform(X_bc)\n",
        "pca_bc_sc = PCA(n_components=0.9)\n",
        "X_bc90_sc = pca_bc_sc.fit_transform(X_bc_sc)\n",
        "print(pca_bc_sc.explained_variance_ratio_)\n",
        "\n",
        "print(f\"Redukcja wymiarowości: {X_bc.shape} => {X_bc90_sc.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bYQCxmLp__l8",
        "outputId": "6d2fe1b0-23bd-4730-8dc9-bee1a4b328ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.98204467]\n",
            "[0.44272026 0.18971182 0.09393163 0.06602135 0.05495768 0.04024522\n",
            " 0.02250734]\n",
            "Redukcja wymiarowości: (569, 30) => (569, 7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Możemy zawuażyć, że nieprzeskalowane dane redukują się do 1 wymiaru o bardzo dużej wariancji. Może to wynikać z faktu, że niektóre cechy mają dużo większą skalę od innych i model \"sztucznie\" zawyża wariancję dla nich. W przypadku przeskalowanych cech dostajemy już bardziej wiarygodne wyniki."
      ],
      "metadata": {
        "id": "ZXPEeAVoHVSl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# iris dataset\n",
        "X_ir = data_iris.data\n",
        "y_ir = data_iris.target\n",
        "pca_ir = PCA(n_components=0.9)\n",
        "X_ir90 = pca_ir.fit_transform(X_ir)\n",
        "print(pca_ir.explained_variance_ratio_)\n",
        "print(f\"Redukcja wymiarowości: (nieprzeskalowana) {X_ir.shape} => {X_ir90.shape}\")\n",
        "# Scale the data to get better results\n",
        "X_ir_sc = StandardScaler().fit_transform(X_ir)\n",
        "pca_ir_sc = PCA(n_components=0.9)\n",
        "X_ir90_sc = pca_ir_sc.fit_transform(X_ir_sc)\n",
        "print(pca_ir_sc.explained_variance_ratio_)\n",
        "print(f\"Redukcja wymiarowości: {X_ir_sc.shape} => {X_ir90_sc.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fs0rxdUDAyG_",
        "outputId": "bef9e93a-0e6b-4b28-f056-5649b4434963"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.92461872]\n",
            "Redukcja wymiarowości: (nieprzeskalowana) (150, 4) => (150, 1)\n",
            "[0.72962445 0.22850762]\n",
            "Redukcja wymiarowości: (150, 4) => (150, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Znowu przeskalowane dane wydają się dawać bardziej sensowne wyniki"
      ],
      "metadata": {
        "id": "9Ec9QPvqL7vs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Saving the explained variance ratio to pickle file"
      ],
      "metadata": {
        "id": "YWqIyjteL5G4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "with open(\"pca_bc.pkl\", \"wb\") as file:\n",
        "  pickle.dump(pca_bc_sc.explained_variance_ratio_, file)\n",
        "\n",
        "with open(\"pca_ir.pkl\", \"wb\") as file:\n",
        "  pickle.dump(pca_ir_sc.explained_variance_ratio_, file)"
      ],
      "metadata": {
        "id": "fT-ZIHNPMZzx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calculating which features (indexes) have the highest infuence to our variance"
      ],
      "metadata": {
        "id": "rP7HQbhkQDZU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*pca.components_* zwraca wektory własne macierzy kowariancji, czyli **główne składowe**"
      ],
      "metadata": {
        "id": "JZZ98iO9QP-U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(pca_ir_sc.explained_variance_ratio_[:, np.newaxis])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgA3t6BpOnFo",
        "outputId": "a0f9bbd7-593e-470e-f8fd-c92c6dfc8bb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.72962445]\n",
            " [0.22850762]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# components_ is 2D array so we have to reshape our variance_ratio array from 1D to 2D\n",
        "weighted_components = pca_bc_sc.components_ * pca_bc_sc.explained_variance_ratio_.reshape(-1, 1)\n",
        "combined_weights = np.sum(np.abs(weighted_components), axis=0)\n",
        "sorted_index = np.argsort(combined_weights)[::-1] #[::-1] to make get descending order (ascending default)\n",
        "sorted_index = list(dict.fromkeys(sorted_index))\n",
        "\n",
        "with open(\"idx_bc.pkl\", \"wb\") as file:\n",
        "  pickle.dump(sorted_index, file)\n",
        "print(sorted_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nLWV--40OuzF",
        "outputId": "f365090d-4d21-4f2e-f21b-2f6aed51b32c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[np.int64(13), np.int64(25), np.int64(10), np.int64(12), np.int64(15), np.int64(29), np.int64(26), np.int64(4), np.int64(17), np.int64(2), np.int64(0), np.int64(24), np.int64(3), np.int64(22), np.int64(20), np.int64(16), np.int64(23), np.int64(5), np.int64(28), np.int64(19), np.int64(8), np.int64(7), np.int64(27), np.int64(6), np.int64(18), np.int64(9), np.int64(14), np.int64(21), np.int64(1), np.int64(11)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weighted_components = pca_ir_sc.components_ * pca_ir_sc.explained_variance_ratio_.reshape(-1, 1)\n",
        "combined_weights = np.sum(np.abs(weighted_components), axis=0)\n",
        "sorted_index = np.argsort(combined_weights)[::-1] #[::-1] to make get descending order (ascending default)\n",
        "sorted_index = list(dict.fromkeys(sorted_index))\n",
        "\n",
        "with open(\"idx_ir.pkl\", \"wb\") as file:\n",
        "  pickle.dump(sorted_index, file)\n",
        "print(sorted_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UgGSSYZOUDDK",
        "outputId": "97aceeac-f825-4a6a-d270-b0d1afd463bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[np.int64(0), np.int64(2), np.int64(3), np.int64(1)]\n"
          ]
        }
      ]
    }
  ]
}